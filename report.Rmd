---
title: "Final Report"
author: "Chrysa Papadopoulou"
date: "12/19/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The class SingleCellExperiment keeps track of the counts and their associated metadata within a single object.

![](SingleCellExperiment_class.png)

```{r,message = FALSE}
library(SingleCellExperiment)
sce <- readRDS("week13_SCE_clustered.rds")
sce
```

## Preprocessing

### Quality control on the cells

Low-quality cells produce technical effects that can distort the downstream analysis results. Therefore, we use Quality Control (QC) metrics to detect and remove them. We implement the above steps:

* 1. Remove undetected genes

```{r}
# remove undetected genes
sce <- sce[rowSums(counts(sce) > 0) > 0, ]
dim(sce)
```

[Scater](http://bioconductor.org/packages/release/bioc/html/scater.html) provides functionality for three levels of quality control:

* QC and filtering of cells
* QC and filtering of features (genes)
* QC of experimental variables

### Cell-level QC

We compute various per-cell quality control metrics using the perCellQCMetrics() function, which includes:

* sum: total number of counts for the cell (i.e., the library size).
* detected: the number of features for the cell that have counts above the detection limit (default of zero).
* subsets_X_percent: percentage of all counts that come from the feature control set named X.

```{r,message = FALSE}
library(scater)
per.cell <- perCellQCMetrics(sce, subsets=list(Mito=grep("ENSM", rownames(sce))))
summary(per.cell$sum)
```

```{r}
summary(per.cell$detected)
```

```{r}
summary(per.cell$subsets_Mito_percent)
```

```{r}
colData(sce) <- cbind(colData(sce), per.cell)
```

We expect to see an increasing number of detected genes with increasing total count. Each point represents a cell that is coloured according to its phenoid.

```{r}
plotColData(sce, x = "sum", y="detected",colour_by="cluster_id")
```

* 2. Remove cells with very few or many detected genes based on outliers

Picking a threshold for these metrics is not straightforward as their absolute values depend on the experimental protocol. For instance, sequencing to greater depth will lead to more reads and more expressed features, regardless of the quality of the cells. To obtain an adaptive threshold, we assume that most of the dataset consists of high-quality cells, and identify cells that are outliers for the various QC metrics.

The distributions of QC metrics are shown below. The goal is to remove putative low-quality cells that have very few or many detected genes.

```{r}
par(mfrow=c(2,2), mar=c(5.1, 4.1, 0.1, 0.1))
hist(sce$detected, xlab="Detected Genes", 
    ylab="Number of cells", breaks=20, main="", col="blue")
```
The isOutlier function provides a more data-adaptive way of choosing these thresholds. This defines the threshold at a certain number of median absolute deviations (MADs) away from the median. Values beyond this threshold are considered outliers and can be filtered out, assuming that they correspond to low-quality cells. Here, we define outliers for the log-total counts, log-total features and detected genes at 3 MADs from the median.

```{r}
total.drop <- isOutlier(sce$total, nmads = 2, type = "both", log = TRUE, batch = sce$sample_id)
detected.drop <- isOutlier(sce$detected, nmads=2, type="lower", log=TRUE)
subsets_Mt_percent.drop <- isOutlier(sce$subsets_Mt_percent, nmads = 2, type = "higher") & sce$subsets_Mt_percent > 0.08
sce <- sce[, !(total.drop | detected.drop | subsets_Mt_percent.drop)]
```

Subsetting by column will retain only the high-quality cells that pass the above filter. We inspect the number of cells removed by each filter as well as the total number of retained cells. Removal of a substantial proportion of cells (> 10%) may be indicative of an overall issue with data quality, which is not the case in our analysis.

```{r}
dim(sce)
data.frame(ByDetectedGenes=sum(detected.drop),ByTotal=sum(total.drop),Bysubsets_Mt_percent=sum(subsets_Mt_percent.drop),Remaining=ncol(sce))
```
As it is observed, the isOutlier approach adjusts to experiment-specific aspects of the data, e.g., sequencing depth and cell type. On the other hand, a fixed threshold would require manual adjustment to account for changes to the experimental protocol or system.

* 3. Remove low-abundance/lowly expressed genes

### Feature-level QC

Feature-level metrics are computed by the perFeatureQCMetrics() function and include:

* mean: the mean count of the gene/feature across all cells.
* detected: the percentage of cells with non-zero counts for each gene.
* subsets_Y_ratio: ratio of mean counts between the cell control set named Y and all cells.


```{r}
per.feat <- perFeatureQCMetrics(sce)
summary(per.feat$mean)
```
```{r}
summary(per.feat$detected)
```

```{r}
summary(per.feat$subsets_Empty_ratio)
```
Adjustment of counts by the relative library size (or size factor) prior to taking the mean.

Several metrics can be utilized to define low-abundance genes. Here, we use the average count for each gene, computed across all cells in the data set, using the calcAverage function, which also performs some adjustment for library size differences between cells.


```{r}
ave <- calculateAverage(sce)
summary(ave)
```

```{r}
hist(log10(ave), breaks=100, main="", col="blue", 
    xlab=expression(Log[10]~"average count"))
```

A minimum threshold can be applied to filter out genes that are lowly expressed. The example below demonstrates how we could remove genes with average counts less than 1. The number of TRUE values in demo.keep corresponds to the number of retained rows/genes after filtering.


```{r}
keep <- ave >= 1
filtered.sce <- sce[keep,]
summary(keep)
```

We also examine the number of cells that express each gene. This is closely related to the average count for most genes, as expression in many cells will result in a higher average. Genes expressed in very few cells are often uninteresting as they are driven by amplification artifacts (though they may also also arise from rare populations). We could then remove genes that are expressed in fewer than n cells.

```{r}
summary(nexprs(sce, byrow=TRUE))
```

```{r}
num.cells <- nexprs(sce, byrow=TRUE)
smoothScatter(log10(ave), num.cells, ylab="Number of cells", 
    xlab=expression(Log[10]~"average count"))
```

In this plot we can observe the number of cells expressing each gene, plotted against the log-average count. Intensity of colour corresponds to the number of genes at any given location.

We remove genes that are not expressed in any cell to reduce computational work in downstream steps. Such genes provide no information and would be removed by any filtering strategy.

### Identifying the most highly expressed genes

We look at a plot that shows the top 50 (by default) most-expressed features. Each row in the plot below corresponds to a gene, and each bar corresponds to the expression of a gene in a single cell. The circle indicates the median expression of each gene, with which genes are sorted.

```{r}
plotHighestExprs(sce, exprs_values = "counts")
```

```{r}
# remove lowly expressed genes
sce <- sce[rowSums(counts(sce) > 1) >= 10, ]
dim(sce)
```

### Variable-level QC
Variable-level metrics are computed by the getVarianceExplained() function and calculate the percentage of variance of each geneâ€™s expression that is explained by each variable in the colData of the sce.

```{r}
counts <- assay(sce, "counts")
libsizes <- colSums(counts)
size.factors <- libsizes/mean(libsizes)
logcounts(sce) <- log2(t(t(counts)/size.factors) + 1)
assayNames(sce)
vars <- getVarianceExplained(sce, 
    variables=c("sample_id", "group_id", "cluster_id","sum","detected","percent_top_50","subsets_Mt_percent"))
head(vars)
```     

We can then use this to determine which experimental factors are contributing most to the variance in expression. This is useful for diagnosing batch effects or to quickly verify that a treatment has an effect.

```{r}
plotExplanatoryVariables(vars)
```

The aforementioned density plot shows the percentage of variance explained by the plotted variables. For each gene, the percentage of the variance of the normalized log-expression values across cells that is explained by each factor is calculated. Each curve corresponds to one factor and represents the distribution of percentages across all genes. The percentages are generally small (0.08%,0.1%, 0.5%) indicating that the expression profiles of most genes are not strongly associated with these factors.

## Computing expression values

### Normalization for library size differences

We use logNormCounts(), which calculates log2-transformed normalized expression values by dividing each count by its size factor, adding a pseudo-count of 1 and log-transforming. The resulting values can be interpreted on the same scale as log-transformed counts, and are stored in "logcounts".

By default, the size factor is automatically computed from the library size of each cell using the librarySizeFactors() function. This calculation simply involves scaling the library sizes so that they have a mean of 1 across all cells.
```{r}
summary(librarySizeFactors(sce))
```

Alternatively, we can calculate counts-per-million using the aptly-named calculateCPM() function. The output is most appropriately stored as an assay named "cpm" in the assays of the SingleCellExperiment object.

```{r}
cpm(sce) <- calculateCPM(sce)
```

```{r norm}
# compute sum-factors & normalize
sce <- computeLibraryFactors(sce)
sce <- logNormCounts(sce)
```

## Visualize expression values
The plotExpression() function makes it easy to plot expression values for a subset of genes or features.

Setting x will determine the covariate to be shown on the x-axis. We have visulalized the expression values of all features in order to obtain the expression profile across cells.

```{r}
plotExpression(sce, rownames(sce)[1:6], x = "cluster_id",colour_by="cluster_id")
```

## Muscat Analysis [following](https://github.com/HelenaLC/muscat/blob/master/vignettes/vignette.Rmd) [and](https://github.com/HelenaLC/BC2_2019-workshop_multi-scRNA-seq/blob/master/LPS/analysis/3-differential.Rmd)
```{r}
# make WT reference group
sce$group_id <- relevel(sce$group_id, ref = "WT")
```

```{r}
# reorder sample levels
m <- match(levels(sce$sample_id), sce$sample_id)
o <- order(sce$group_id[m])
sce$sample_id <- factor(sce$sample_id, levels = levels(sce$sample_id)[o])
```

```{r}
# prep. SCE for 'muscat'
library(muscat)
sce <- prepSCE(sce,
  cluster_id = "cluster_id",
  sample_id = "sample_id",
  group_id = "group_id",
  drop = FALSE)
```

Westore cluster and sample IDs, as well as the number of clusters and samples into the following variables:
```{r ids}
nk <- length(kids <- levels(sce$cluster_id))
ns <- length(sids <- levels(sce$sample_id))
names(kids) <- kids; names(sids) <- sids
```

### Cluster-sample sizes
As we will be aggregating measurements at the cluster-sample level, it is crucial to check the number of cells captured for each such instance. While `aggregateData` allows excluding cluster-sample combinations with less than a threshold number of cells, clusters or samples with overall very low cell-counts may be excluded from further analysis at this point already.

```{r ncells, size = "small"}
# nb. of cells per cluster-sample
t(table(sce$cluster_id, sce$sample_id))
```

## Dimensionality reduction

In scRNA-seq analysis, dimensionality reduction is often used as a preliminary step prior to downstream analyses, such as clustering, cell lineage and pseudotime ordering, and the identification of DE genes. This allows the data to become more tractable, both from a statistical (cf. curse of dimensionality) and computational point of view. Additionally, technical noise can be reduced while preserving the often intrinsically low-dimensional signal of interest (Dijk et al. 2017; Pierson and Yau 2015; Risso et al. 2018b).

```{r}
# wrapper to prettify reduced dimension plots
.plot_dr <- function(sce, dr, col)
  plotReducedDim(sce, dimred = dr, colour_by = col) +
    guides(fill = guide_legend(override.aes = list(alpha = 1, size = 3))) +
    theme_minimal() + theme(aspect.ratio = 1)
```

## t-SNE method
t-distributed stochastic neighbour embedding (t-SNE) is widely used for visualizing complex single-cell data sets. The same procedure described for PCA plots can be applied to generate t-SNE plots using plotTSNE, with coordinates obtained using runTSNE via the Rtsne package. We strongly recommend generating plots with different random seeds and perplexity values, to ensure that any conclusions are robus t to different visualizations.

```{r,message=FALSE}
library("Rtsne")
# Perplexity of 20 just chosen here arbitrarily.
set.seed(1000)
sce <- runTSNE(sce, perplexity=20)
w_tsne<-reducedDim(sce, "TSNE")
head(w_tsne)
```

In our analysis, the t-SNE and UMAP colored by `cluster_id`s show that cell-populations are well-separated from one another. IFN-$\beta$ stimulation manifests as a severe shift in the low-dimensional projection of cells when coloring by `group_id`s, indicating widespread, genome-scale transcriptiontal changes.

```{r eval = FALSE}
library(cowplot)
# downsample to max. 100 cells per cluster
cs_by_k <- split(colnames(sce), sce$cluster_id)
cs100 <- unlist(sapply(cs_by_k, function(u) 
  sample(u, min(length(u), 100))))
# plot t-SNE & UMAP colored by cluster & group ID
for (dr in c("TSNE", "UMAP","PCA"))
  for (col in c("cluster_id", "group_id"))
    .plot_dr(sce[, cs100], dr, col)
```


```{r dr-ids, echo = FALSE, results = "asis", fig.height = 4, fig.width = 12, fig.cap = "Dimension reduction plots. Cells are colored by cluster ID (A) and group ID (B), respectively. For each cluster, at most 100 cells were sampled for plotting."}
library(grid)
library(cowplot)
cs_by_k <- split(colnames(sce), sce$cluster_id)
cs100 <- unlist(sapply(cs_by_k, function(u) 
  sample(u, min(length(u), 100))))
for (dr in c("TSNE", "UMAP","PCA")) {
  cat("#### ", dr, "{-}\n")
  ps <- lapply(c("cluster_id", "group_id"), 
    function(col) .plot_dr(sce[, cs100], dr, col = col))
  assign(paste0("ps_", tolower(dr)), ps)
  print(plot_grid(plotlist = ps, align = "vh", labels = c("A", "B")))
  cat("\n\n")
}
```


To test for state changes across conditions, we will consider two types of approaches: i) mixed models that act directly on cell-level measurements; and ii) aggregation-based methods that act on *pseudobulk* data. For both approaches, each gene is tested for state changes in each cluster. Thus, a total of $\#(genes) \times \#(clusters)$ tests will be performed per comparison of interest.

* Aggregation to pseudobulk sum of counts
* Pseuobulk-level MDS plot
* DS analysis with `muscat`
* Reformatting & filtering of results
* Sample-level viz.: Pseudobulk-level heatmap
* Cell-level viz.: Violin plots
* Upset plot intersecting DS gene across clusters


We first can aggregate measurements for each sample (in each cluster) to obtain pseudobulk data.

```{r}
#Aggregation of single-cell to pseudobulk data
compute.pd <- function(sce,assay,fun){
  pb <- aggregateData(sce,assay = assay, fun = fun,
    by = c("cluster_id", "sample_id"))
  
  # one sheet per subpopulation
  print(assayNames(pb))
  # pseudobulks for 1st subpopulation
  print(t(head(assay(pb))))
  return(pb)
}
```


## Sample level-Differential State analysis  : Pseudobulk methods {#sec-pbDS}

Firstly, we filter the results to retain hits FDR < 5\% and abs(logFC) > 1, and count the number and frequency of differential findings by cluster. Finally, we can view the top hits (lowest adj. p-value) in each cluster.

```{r ds}

DS.analysis.pd <- function(pb,sce){
  library(dplyr)
  library(scater)
  library(UpSetR)
  # run edgeR on pseudobulks
  res <- pbDS(pb, method = "edgeR", verbose = FALSE)
  res <- pbDS(pb, method = "limma-voom", verbose = FALSE)
 
  # reformat results
  tbl <- resDS(sce, res, bind = "col")
  # filter & sort
  tbl <- filter(tbl,tbl$p_adj.loc < 0.05, tbl$logFC > 1)
  tbl <- arrange(tbl, tbl$p_adj.loc)
  # no. of DS genes per cluster
  res_by_k <- split(tbl, tbl$cluster_id)
  vapply(res_by_k, nrow, numeric(1))
  # top hits in ea. cluster
  top <- do.call("rbind", lapply(res_by_k, head, 3))
  top <- select(top, -c("contrast", "p_adj.glb"))
  top$gene <- gsub("^.*\\.", "", top$gene)
  print(format(data.frame(top, row.names = NULL), digits = 3))
  
  return(list(sce = sce,res = res ,tbl = tbl,res_by_k = res_by_k))
  
}
```

## Calculating expression frequencies

Besides filter DS results based on magnitude (logFCs) and significance (FDR), it is often worthwhile to also consider the expression frequencies of each gene, i.e., the fraction of cells that express a given gene in each sample and/or group.  
We use `calcExprFreqs` to compute cluster-sample/-group wise expression frequencies. Here, a gene is considered to be expressed when the specified measurement value (argument `assay`) falls above a certain threshold (argument `th`). Note that, `assay = "counts"` and `th = 0` (default) amounts to the fraction of cells for which a respective gene has been detected.  


## Violin Plots

We generate violin plots for the top-8 DS genes (lowest adj. p-value) for all clusters.
Each violin is a sample; points are colored by group ID. As DS testing is done at the cluster-level, we need to subset the cells that have been assigned to the corresponding cluster for plotting. 


## DR colored by expression

The code chunk generates a set of t-SNEs colored by gene expression for the top-8 DS genes. To match the affected cells to their cluster and experimental group, see the t-SNEs colored by cluster and group ID from above.

```{r}
 DR.colored.by.expression<-function(sce,tbl){
   top8 <- bind_rows(tbl) %>% 
     top_n(8, dplyr::desc(p_adj.loc)) %>% 
   pull("gene")
# for ea. gene in 'top8', plot t-SNE colored by its expression 
   ps <- lapply(top8, function(g).plot_dr(sce[, cs100], "TSNE", g) + 
       ggtitle(g) + theme(legend.position = "none"))
  # arrange plots
   plot_grid(plotlist = ps, ncol = 4, align = "vh")
 }

```


```{r}
DS.analysis.Visualization <-function(sce,assay,fun){
  #Aggregation of single-cell to pseudobulk data for sum counts
  pb <- compute.pd(sce,assay,fun) 
  # Pseudobulk-level multidimensional scaling (MDS) plot. Each point represents a cluster-sample instance; points are colored by cluster ID and shaped by group ID
  (pb_mds <- pbMDS(pb))
  
  ds <- DS.analysis.pd(pb,sce)
  sce <- ds$sce
  res <-ds$res
  tbl <- ds$tbl
  res_by_k <- ds$res_by_k

  frq <- calcExprFreqs(sce, assay = assay, th = 0)
  # one sheet per cluster
  assayNames(frq)
  # expression frequencies in each
  # sample & group; 1st cluster
  print(t(head(assay(frq), 5)))

  ### Pseudobulk-level heatmap
  
  ##TODO Heatmaps not shown
  
  # single gene across all clusters
  # top-20 DS genes for single cluster
  pbHeatmap(sce, res, k = "Astrocytes")
  pbHeatmap(sce, res, k = "Oligodendrocytes")
  pbHeatmap(sce, res, k = "OPC")
  pbHeatmap(sce, res, k = "Neuronal_excit")
  pbHeatmap(sce, res, k = "Microglia")
 
  # TODO top-5 DS genes per cluster
  #pbHeatmap(sce, res, top_n = 5)
  
  
  ### Violin Plots
  ## TO DO for all cell types 
  # split cells by cluster
  #cell_types <- unique(sce$cluster_id)
#  for(i in cell_types){
  cs_by_k <- split(colnames(sce), sce$cluster_id)
  plotExpression(sce[, cs_by_k$Endothelial], 
    features = res_by_k$Endothelial$gene[seq_len(8)],
    x = "sample_id", colour_by = "group_id") + theme_classic() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
# }
  
  ### TO DO Between-cluster concordance
  ds_gs <- lapply(res_by_k, pull, "gene")
  #upset(fromList(ds_gs), sets = levels(sce$cluster_id))
  
 ### DR colored by expression
  
  DR.colored.by.expression(sce,tbl)

  ### Write results to .rds
  getwd()
  saveRDS(res, file.path("output", "DS_results.rds"))
    
  
}

#DS Analysis for sum counts
DS.analysis.Visualization(sce,"counts","sum")

#DS Analysis for mean logcounts
#DS.analysis.Visualization(sce,"logcounts","mean")
```


## Cell-level analysis: Mixed models {#sec-mmDS}

We can fit for each gene a mixed model to the cell-level measurement data.

1. fitting linear mixed models (LMMs) on log-normalized data with observational weights, 
2. fitting LMMs on variance-stabilized data; and,
3. fitting generalized linear mixed models (GLMMs) directly on counts

In each case, a $\sim 1 + \text{group_id} + (1\,|\,\text{sample_id})$ model is fit for each gene, optimizing the log-likelihood (i.e., `REML = FALSE`). P-values are calculated using the estimates of degrees of freedom specifying by argument `df` (default `"Satterthwaite"`). Fitting, testing and moderation are applied subpopulation-wise. For differential testing, `mmDS` will only consider:

- subpopulations with at least `n_cells` cells (default 10) in at least `n_samples` samples (default 2)
- genes with a count >= `min_count` (default 1) in at least `min_cells` (default 20)

Mixed model based approaches can be run directly on cell-level measurements, and do not require prior aggregation:

TODO : All mm models take ages to run...
```{r mm, eval = FALSE}
# subset "B cells" cluster
#sce_astro <- sce[, sce$cluster_id == "Astrocytes"]
# 1st approach
#mm <- muscat::mmDS(sce_astro, method = "dream",n_cells = 10, n_samples = 2, min_cells = 20)
# 2nd & 3rd approach
#mm <- muscat::mmDS(sce_astro, method = "vst", vst = "sctransform")
#mm <- muscat::mmDS(sce_astro, method = "nbinom")
```




