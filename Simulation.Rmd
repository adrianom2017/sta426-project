---
title: "Simulation"
author: "Adriano Martinelli, Iliana Papadopoulou, Chrysa Papadopoulou"
date: "14/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(SingleCellExperiment)
library(scater)
library(ggplot2)
library(gridExtra)
library(grid)
library(muscat)
sce <- readRDS("Zheng4eq.filt.wPCA.rds")

#Add normalised counts
sce = logNormCounts(sce)
```

## Create correlation structure
```{r}
library("irlba")
sce <- sce[, sce$phenoid == 'b.cells']

# Select kNN = 20 nearest neighbors for each cell
kNN <- 20
N<-5
n_comp = 50 #TODO choose n_comp based on PCA, intrinsicDimensions --> function: maxgloballikelihood
n_treated = floor(985/2)
n_ntreated = 985 - n_treated
n_cells = n_treated + n_ntreated

if(n_cells <= dim(sce)[2]){
  idx_cells = sample(c(1:dim(sce)[2]), n_cells, replace = FALSE)
}else{
  idx_cells = sample(c(1:dim(sce)[2]), n_cells, replace = TRUE)
}

pca_data <- prcomp_irlba(t(logcounts(sce)),n = n_comp)

#Create distance matrix
distance_matrix<-as.matrix(dist(pca_data$x,method="euclidean"))
diag(distance_matrix) = Inf

#Sort distance matric by row
sorted_distances <- apply(distance_matrix,1,function(x) sort(x, index.return = T)$ix)

# Select random subsample of neighbors (N=10) from the kNN and average them per PCA dimention
#w_clustered <- apply(sorted_distances,2,function (d) {
#  cell_neighbors <- sample(d[1:kNN], N, replace = TRUE)
#  colMeans(pca_data$x[cell_neighbors,])
#  })

# Select random subsample of neighbors (N=10) from the kNN and average them per PCA dimention
w_clustered <- sapply(idx_cells, function (idx) {
  d = sorted_distances[idx,1:kNN]
  cell_neighbors <- sample(d, N, replace = TRUE)
  colMeans(pca_data$x[cell_neighbors,])
  })

w_clustered = t(w_clustered)

#TODO check transpose https://stackoverflow.com/questions/29783790/how-to-reverse-pca-in-prcomp-to-get-original-data
expression_matrix <- t(w_clustered  %*% t(pca_data$rotation)) + pca_data$center
dim(expression_matrix)

```

## Logfold change
```{r}
#Define amount of DE genes
DE_portion = 0.01

#Define logfold change for (not) DE genes
fc = 0
DE_fc = 4

#TODO fun should accept list of logFC

#select DE genes
idx = sample(c(1:dim(sce)[1]), floor(DE_portion*dim(sce)[1]))
log2FC = rep(fc, dim(sce)[1])
log2FC[idx] = DE_fc 
```

## Calculate dispersion
```{r}
library(edgeR)
dds <- DGEList(counts(sce))
mm <- model.matrix(~1, data=as.data.frame(colData(sce)))
dds <- estimateDisp(dds, mm)
rowData(sce)$dispersion <- dds$tagwise.dispersion
```

```{r}
#TODO set library size
colD = data.frame('cluster_id' = 'b.cells',
                  'treatment' = c(rep(1, n_treated), rep(0, n_ntreated)),
                  'library_size' = NA)
rowD = data.frame('logFC' = log2FC, 'Dispersion' = dds$tagwise.dispersion)
```


```{r}
#TODO: How to deal with the +1 in the logtransform?
c = 2^expression_matrix - 1

sce_sim <- SingleCellExperiment(assays = list(logcounts = expression_matrix,
                                              counts = c))
colData(sce_sim) =  cbind(colData(sce_sim), colD)
rowData(sce_sim) = cbind(rowData(sce_sim), rowD)

rownames(sce_sim)<-rownames(sce)
cell_id <-colnames(sce)[idx_cells]
colData(sce_sim) = cbind(colData(sce_sim), cell_id) #TODO append .#
```

## Calculate count matrix via NB distribution
```{r}
ds = rep(rowData(sce_sim)$Dispersion, each = ncol(sce_sim)) 

#TODO: why do you transpose?
mu = c(counts(sce_sim)) * 2^rowData(sce_sim)$logFC

#TODO: How to use the dispersion param?
counts =  rnbinom(n=nrow(sce_sim)*ncol(sce_sim), size=1/ds, mu=mu)
counts = matrix(counts, nrow = nrow(sce_sim),ncol = ncol(sce_sim))
assay(sce_sim, 'sim_counts') = counts

#x = seq(0:100)
#qplot(x, dnbinom(x,size = ds[1], mu = mu[1]))

#TODO scatter plot of expected mean vs observed mean.
```

## Calculate library size
```{r}
colData(sce_sim)$library_size <- colSums(assay(sce_sim, 'sim_counts'))
```

## DE analysis, edgeR
```{r}
#TODO: How to get samples, how many samples should we simulate.

# Data set: week13
# params: 
# - kNN
# - #samples per group (treatment)
# - #n_comp or estimation
# - #subset of knn
# - magnitute logFC + proportion or list of logFC half of it should be inversed.

# aggregateData -> pbDS(method=edgeR)
#  - sum counts
#  - mean of logcounts
# aggregateData (sum counts)-> pbDS(method="limma-voom")
# mmDS(method="dream")
# mmDS(method="vst")
# mmDS(method="nbinom")

# Compare DE results 
# Compare ranking of simulations
# Upset 
# TPR-FDR

# Comparison of data sets
# t-SNE --> scater Run tsne
# countSimQC package

library(limma)
library(edgeR)

grp = colData(sce_sim)$treatment
grp = factor(grp)

y <- DGEList(counts=assay(sce_sim, 'sim_counts'),group=grp)
y <- calcNormFactors(y)
design <- model.matrix(~grp)

y <- estimateDisp(y,design)

#To perform likelihood ratio tests:
fit <- glmFit(y,design)
lrt <- glmLRT(fit,coef=2)
topTags(lrt)
```
## DE analysis, limma
```{r}



```

