---
title: "Simulation"
author: "Adriano Martinelli, Iliana Papadopoulou, Chrysa Papadopoulou"
date: "14/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, messages = FALSE)
```

```{r}
library(SingleCellExperiment)
library(scater)
library(ggplot2)
library(gridExtra)
library(grid)
library(muscat)
sce <- readRDS("Zheng4eq.filt.wPCA.rds")

#Add normalised counts
sce = logNormCounts(sce)
```

## Create correlation structure
```{r}
library("irlba")
library(intrinsicDimension)
sce <- sce[, sce$phenoid == 'b.cells']

# Select kNN = 20 nearest neighbors for each cell
kNN <- 20
N<-5
n_comp = 50 #TODO choose n_comp based on PCA, intrinsicDimensions --> function: maxgloballikelihood
n_treated = floor(985/2)
n_ntreated = 985 - n_treated
n_cells = n_treated + n_ntreated

if(n_cells <= dim(sce)[2]){
  idx_cells = sample(c(1:dim(sce)[2]), n_cells, replace = FALSE)
}else{
  idx_cells = sample(c(1:dim(sce)[2]), n_cells, replace = TRUE)
}

pca_data <- prcomp_irlba(t(logcounts(sce)),n = n_comp)

#Create distance matrix
distance_matrix<-as.matrix(dist(pca_data$x,method="euclidean"))
diag(distance_matrix) = Inf

#Sort distance matric by row
sorted_distances <- apply(distance_matrix,1,function(x) sort(x, index.return = T)$ix)

# Select random subsample of neighbors (N=10) from the kNN and average them per PCA dimention
#w_clustered <- apply(sorted_distances,2,function (d) {
#  cell_neighbors <- sample(d[1:kNN], N, replace = TRUE)
#  colMeans(pca_data$x[cell_neighbors,])
#  })

# Select random subsample of neighbors (N=10) from the kNN and average them per PCA dimention
w_clustered <- sapply(idx_cells, function (idx) {
  d = sorted_distances[idx,1:kNN]
  cell_neighbors <- sample(d, N, replace = TRUE)
  colMeans(pca_data$x[cell_neighbors,])
  })

w_clustered = t(w_clustered)

#TODO check transpose https://stackoverflow.com/questions/29783790/how-to-reverse-pca-in-prcomp-to-get-original-data
expression_matrix <- t(w_clustered  %*% t(pca_data$rotation)) + pca_data$center
dim(expression_matrix)

```

## Logfold change
```{r}
#Define amount of DE genes
DE_portion = 0.01

#Define logfold change for (not) DE genes
fc = 0
DE_fc = 4

#TODO fun should accept list of logFC

#select DE genes
idx = sample(c(1:dim(sce)[1]), floor(DE_portion*dim(sce)[1]))
log2FC = rep(fc, dim(sce)[1])
log2FC[idx] = DE_fc 
```

## Calculate dispersion
```{r}
library(edgeR)
dds <- DGEList(counts(sce))
mm <- model.matrix(~1, data=as.data.frame(colData(sce)))
dds <- estimateDisp(dds, mm)
rowData(sce)$dispersion <- dds$tagwise.dispersion
```

```{r}
#TODO set library size
colD = data.frame('cluster_id' = 'b.cells',
                  'treatment' = c(rep(1, n_treated), rep(0, n_ntreated)),
                  'library_size' = NA)
rowD = data.frame('logFC' = log2FC, 'Dispersion' = dds$tagwise.dispersion)
```


```{r}
#TODO: How to deal with the +1 in the logtransform?
c = 2^expression_matrix - 1

sce_sim <- SingleCellExperiment(assays = list(logcounts = expression_matrix,
                                              counts = c))
colData(sce_sim) =  cbind(colData(sce_sim), colD)
rowData(sce_sim) = cbind(rowData(sce_sim), rowD)

rownames(sce_sim)<-rownames(sce)
cell_id <-colnames(sce)[idx_cells]
colData(sce_sim) = cbind(colData(sce_sim), cell_id) #TODO append .#
```

## Calculate count matrix via NB distribution
```{r}
ds = rep(rowData(sce_sim)$Dispersion, each = ncol(sce_sim)) 

#TODO: why do you transpose?
mu = c(counts(sce_sim)) * 2^rowData(sce_sim)$logFC

#TODO: How to use the dispersion param?
counts =  rnbinom(n=nrow(sce_sim)*ncol(sce_sim), size=1/ds, mu=mu)
counts = matrix(counts, nrow = nrow(sce_sim),ncol = ncol(sce_sim))
assay(sce_sim, 'sim_counts') = counts

#x = seq(0:100)
#qplot(x, dnbinom(x,size = ds[1], mu = mu[1]))

#TODO scatter plot of expected mean vs observed mean.
```

## Calculate library size
```{r}
colData(sce_sim)$library_size <- colSums(assay(sce_sim, 'sim_counts'))
```

## DE analysis, edgeR
```{r}
#TODO: How to get samples, how many samples should we simulate.

# Data set: week13
# params: 
# - kNN
# - #samples per group (treatment)
# - #n_comp or estimation
# - #subset of knn
# - magnitute logFC + proportion or list of logFC half of it should be inversed.

# aggregateData -> pbDS(method=edgeR)
#  - sum counts
#  - mean of logcounts
# aggregateData (sum counts)-> pbDS(method="limma-voom")
# mmDS(method="dream")
# mmDS(method="vst")
# mmDS(method="nbinom")

# Compare DE results 
# Compare ranking of simulations
# Upset 
# TPR-FDR

# Comparison of data sets
# t-SNE --> scater Run tsne
# countSimQC package

library(limma)
library(edgeR)

grp = colData(sce_sim)$treatment
grp = factor(grp)

y <- DGEList(counts=assay(sce_sim, 'sim_counts'),group=grp)
y <- calcNormFactors(y)
design <- model.matrix(~grp)

y <- estimateDisp(y,design)

#To perform likelihood ratio tests:
fit <- glmFit(y,design)
lrt <- glmLRT(fit,coef=2)
topTags(lrt)
```

## Load data
```{r}
suppressPackageStartupMessages({
library(SingleCellExperiment)
library(scater)
library(ggplot2)
library(gridExtra)
library(grid)
library(edgeR)
library(irlba)
library(muscat)
library(countsimQC)})

#Load object
sce = readRDS("week13_SCE_clustered.rds")
sce = logNormCounts(sce)

#Extract WT samples
sce_wt = sce[, colData(sce)$group_id == "WT"]
```

## Run simulation
```{r}
##Prep data for simulation
sce_prep <- prepSCE(sce_wt,
  cluster_id = "cluster_id",
  sample_id = "sample_id",
  group_id = "group_id",
  drop = FALSE)
sce_prep <- prepSim(sce_prep)

n_cluster = length(unique(colData(sce_prep)$cluster_id))
freq_cluster = table(colData(sce_prep)$cluster_id)
freq_cluster = freq_cluster / sum(freq_cluster)
n_sample = length(unique(colData(sce_prep)$sample_id))
n_group = 2

#Set params MUSCAT
n_genes = nrow(sce_prep)
n_cells_muscat = 100*n_sample
p_dd = c(0.9, 0, 0.1, 0, 0, 0)
probs = list(cluster = freq_cluster,
             sample = rep(1/n_sample, n_sample),
             group = rep(1/n_group, n_group))
lcf = 4

#Set params our simulation
n_comp = 10
n_cells = rep(n_cells_muscat / n_sample, n_sample)
kNN = 10
kNN_subsample = 5
logFC = list(magnitude = lcf, proportion = p_dd[3]) #corresponds to p_dd
verbose = 2

#Run simulations
sce_muscat = simData(sce_prep, n_genes = n_genes, n_cells = n_cells_muscat, p_dd = p_dd, probs = probs)
sce_sim = create_dataset(sce_prep, n_comp, n_cells, kNN, kNN_subsample, n_sample, logFC, probs, verbose)
```

## Augment data sets
```{r}
#Convert counts
sce_muscat = logNormCounts(sce_muscat)
logcounts(sce_prep) = as.matrix(logcounts(sce_prep))
counts(sce_prep) = as.matrix(counts(sce_prep))

#Populate sce_sim with reducedDim
sce_sim = runPCA(sce_sim)
sce_sim = runUMAP(sce_sim)
sce_sim = runTSNE(sce_sim)

#Populate sce_muscat with reducedDim
sce_muscat = runPCA(sce_muscat)
sce_muscat = runUMAP(sce_muscat)
sce_muscat = runTSNE(sce_muscat)

#Populate sce_wt with reducedDim
sce_prep = runPCA(sce_prep)
sce_prep = runUMAP(sce_prep)
sce_prep = runTSNE(sce_prep)
```

## Compare simulations
```{r}
subsample = sample(1:ncol(sce_prep), ncol(sce_sim))
  
#Distribution of counts
par(mfrow=c(3,1))
hist(logcounts(sce_prep)[sample(1:nrow(sce_prep), nrow(sce_sim))])
hist(logcounts(sce_muscat))
hist(logcounts(sce_sim))

#Sum of counts
countSum = data.frame(sce_prep = sum(counts(sce_prep)[,subsample]),
                      sce_muscat = sum(counts(sce_muscat)),
                      sce_sim = sum(counts(sce_sim)))
barplot(as.matrix(countSum), main = "Count sum of different SingleCellExperiment data sets")

#Plot dim reductions
par(mfrow=c(3,1))
plotReducedDim(sce_prep, "PCA", colour_by = "cluster_id")
plotReducedDim(sce_muscat, "PCA", colour_by = "cluster_id", shape_by = "group_id")
plotReducedDim(sce_sim, "PCA", colour_by = "cluster_id", shape_by = "group_id")

par(mfrow=c(3,1))
plotReducedDim(sce_prep, "UMAP", colour_by = "cluster_id")
plotReducedDim(sce_muscat, "UMAP", colour_by = "cluster_id", shape_by = "group_id")
plotReducedDim(sce_sim, "UMAP", colour_by = "cluster_id", shape_by = "group_id")

par(mfrow=c(3,1))
plotReducedDim(sce_prep, "TSNE", colour_by = "cluster_id")
plotReducedDim(sce_muscat, "TSNE", colour_by = "cluster_id", shape_by = "group_id")
plotReducedDim(sce_sim, "TSNE", colour_by = "cluster_id", shape_by = "group_id")

#Cell-cell correlation structure
CellCellCor = list("sce_prep" = cor(counts(sce_prep)[,subsample]),
                   "sce_muscat" = cor(counts(sce_muscat)),
                   "sce_sim" = cor(counts(sce_sim)))

x = 1:ncol(sce_muscat)
par(mfrow = c()mar = c(5,6,6,4), cex = 0.5)
image(x,x,CellCellCor$sce_muscat, axes = FALSE, xlab = '', ylab = '')

#Gene-Gene correlation structure
#GeneGeneCor = list("sce_prep" = cor(t(counts(sce_prep)[,subsample])),
#                   "sce_muscat" = cor(t(counts(sce_muscat))),
#                   "sce_sim" = cor(t(counts(sce_sim))))

# x = 1:nrow(sce_muscat)
# par(mar = c(5,6,6,4), cex = 0.5)
# image(x,x,GeneGeneCor$sce_muscat, axes = FALSE, xlab = '', ylab = '')

```

## Compare sim and original data
```{r}
#TODO countSimQC package
```


## DE analysis
```{r}
#TODO implement your functions
```

## Plots
```{r}
library(iCOBRA)
tbl = readRDS("tbl")
cat = as.vector(tbl$category)
cat[cat == "de"] = 1
cat[cat == "ee"] = 0
cat = as.numeric(cat)
tbl$category = cat

#TODO
#FDR vs TPR for each DE analysis method (limma, edgeR,...)
#Upset plot for each DE analysis method. Compare found DE genes vs true DE genes

```

